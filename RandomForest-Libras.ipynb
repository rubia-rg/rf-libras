{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forest + LIBRAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook covers a Python-based solution to be compared to the experiments 1 to 4 presented in <cite data-cite=\"6013574/XD5B9TZQ\"></cite>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Context"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Solution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The presented solution consists in reproducing the feature vectors for each of the experiments utilizing (x, y) points in <cite data-cite=\"6013574/XD5B9TZQ\"></cite>, applying a RandomForest classifier, and lastly, comparing the resulting performance to the ones obtained by SVM and k-NN approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import glob as gl\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def labelname(file_name):  # Extract labels from filenames \n",
    "    label = file_name.replace(\"data/points/sample\", \"\").lower()\n",
    "    return label.replace(\".mat\", \"\")\n",
    "\n",
    "\n",
    "class Signal:  # Signal representation containing x and y coordinates and corresponding label\n",
    "    def __init__(self, x, y, label):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first experiment utilizes each signal in its raw form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigvalues(sig):  # EX.1: raw data\n",
    "    updsig = np.zeros((np.shape(sig.x)[0], np.shape(sig.x)[1] * 2))\n",
    "    updsig[:, ::2] = sig.x\n",
    "    updsig[:, 1::2] = sig.y\n",
    "\n",
    "    return updsig  # Updated signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second experiment consists of applying z-normalization to each sample. The updated coordinates are:\n",
    "\\begin{align}\n",
    "x_{\\mathcal{N(0,1)}}=\\frac{x-\\bar{x}}{\\sigma(x)} \\\\\n",
    "y_{\\mathcal{N(0,1)}}=\\frac{y-\\bar{y}}{\\sigma(y)}\n",
    "\\end{align}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigvalues(sig):  # EX.2: z-norm\n",
    "    updsig = np.zeros((np.shape(sig.x)[0], np.shape(sig.x)[1] * 2))\n",
    "    for idx, x in enumerate(sig.x):\n",
    "        sig.x[idx] = np.divide((np.transpose(x) - np.mean(x)), np.std(x))\n",
    "    for idx, y in enumerate(sig.y):\n",
    "        sig.y[idx] = np.divide((np.transpose(y) - np.mean(y)), np.std(y))\n",
    "\n",
    "    updsig[:, ::2] = sig.x\n",
    "    updsig[:, 1::2] = sig.y\n",
    "\n",
    "    return updsig  # Updated signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The third experiment consists of normalizing each signal by its 1st frame centroid, as follows:\n",
    "\\begin{align}\n",
    "\\tilde{x}_{P,f}=x_{P,f}-\\bar{x}_{1} \\\\\n",
    "\\tilde{y}_{P,f}=y_{P,f}-\\bar{y}_{1}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigvalues(sig): # EX.3: norm by 1st frame centroid\n",
    "    frame_x = np.split(sig.x, 5, axis=1)  # x-coordinates by frame\n",
    "    frame_y = np.split(sig.y, 5, axis=1)  # y-coordinates by frame\n",
    "    cent_x, cent_y = (np.mean(frame_x[0], axis=1), np.mean(frame_y[0], axis=1))  # first frame centroid of each recording\n",
    "\n",
    "    updsig = np.zeros((np.shape(sig.x)[0], np.shape(sig.x)[1] * 2))\n",
    "    for idx, x in enumerate(sig.x):\n",
    "        sig.x[idx] = x - cent_x[idx]\n",
    "    for idx, y in enumerate(sig.y):\n",
    "        sig.y[idx] = y - cent_y[idx]\n",
    "\n",
    "    updsig[:, ::2] = sig.x\n",
    "    updsig[:, 1::2] = sig.y\n",
    "\n",
    "    return updsig  # Updated signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The fourth experiment consists of normalizing each signal by its current frame centroid, as follows:\n",
    "\\begin{align}\n",
    "\\tilde{x}_{P,f}=x_{P,f}-\\bar{x}_{f} \\\\\n",
    "\\tilde{y}_{P,f}=y_{P,f}-\\bar{y}_{f}\n",
    "\\end{align}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigvalues(sig):  # EX.4\n",
    "    frame_x = np.split(sig.x, 5, axis=1)  # x-coordinates by frame\n",
    "    frame_y = np.split(sig.y, 5, axis=1)  # y-coordinates by frame\n",
    "    cent_x, cent_y = (np.mean(frame_x, axis=2), np.mean(frame_y, axis=2))  # centroids of each recording\n",
    "\n",
    "    nframes, nrecs, idx = np.shape(frame_x)\n",
    "    updsig = np.zeros((np.shape(sig.x)[0], np.shape(sig.x)[1] * 2))\n",
    "    for fx in range(nframes):\n",
    "        frame_x[fx] = np.transpose(np.transpose(frame_x[fx]) - cent_x[fx])\n",
    "    for fy in range(nframes):\n",
    "        frame_y[fy] = np.transpose(np.transpose(frame_y[fy]) - cent_y[fy])\n",
    "\n",
    "    updsig[:, ::2] = np.hstack(frame_x)\n",
    "    updsig[:, 1::2] = np.hstack(frame_y)\n",
    "\n",
    "    return updsig  # Updated signal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = gl.glob(\"data/points/*.mat\")  # type: list\n",
    "\n",
    "signals = []  # type: List[Signal]\n",
    "\n",
    "for f in files:\n",
    "    data = loadmat(f).get('pontosSinal')\n",
    "    signals.append(Signal(data[:, ::2], data[:, 1::2], labelname(f)))\n",
    "\n",
    "n_signs = len(signals)\n",
    "n_recs, n_x = np.shape(signals[0].x)  # Number of recordings and number of features\n",
    "\n",
    "signals_feat = []  # Updated signals, according to each experiment\n",
    "signals_labels = []\n",
    "labels_dict = {}  # Dictionary of signals' labels, for reference\n",
    "i = 0\n",
    "\n",
    "for s in signals:\n",
    "    signals_feat.append(sigvalues(s))\n",
    "    signals_labels.append([i] * n_recs)\n",
    "    labels_dict[i] = s.label\n",
    "    i += 1\n",
    "    \n",
    "features = np.reshape(signals_feat, (n_signs * n_recs, n_x * 2))\n",
    "labels = np.reshape(signals_labels, (n_signs * n_recs,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start=200, stop=2000, num=10)]\n",
    "# Number of features to consider at every split\n",
    "max_features = ['log2', 'sqrt']\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num=11)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [2, 5, 7]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [1, 2, 4]\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "niter = 30\n",
    "results = []\n",
    "for i in range(niter):\n",
    "    sss = StratifiedShuffleSplit(n_splits=3, test_size=0.2, random_state=42)\n",
    "    sss.get_n_splits(features, labels)\n",
    "\n",
    "    for train_index, test_index in sss.split(features, labels):\n",
    "        train_x, test_x = features[train_index], features[test_index]\n",
    "        train_y, test_y = labels[train_index], labels[test_index]\n",
    "\n",
    "    rf = RandomForestClassifier()\n",
    "    rf_random = RandomizedSearchCV(estimator=rf, param_distributions=random_grid, n_iter=100,\n",
    "                                   cv=3, verbose=1, n_jobs=-1)\n",
    "\n",
    "    rf_random.fit(train_x, train_y)\n",
    "    predictions = rf_random.predict(test_x)\n",
    "\n",
    "    print(\"Best Params :: \"), pprint(rf_random.best_params_)\n",
    "    print(\"Train Accuracy :: \", accuracy_score(train_y, rf_random.predict(train_x)))\n",
    "    print(\"Test Accuracy  :: \", accuracy_score(test_y, predictions) * 100)\n",
    "    print(\"Confusion matrix :: \\n\", confusion_matrix(test_y, predictions), labels=test_y)\n",
    "    print(classification_report(test_y, predictions, target_names=list(labels_dict)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"cite2c-biblio\"></div>"
   ]
  }
 ],
 "metadata": {
  "cite2c": {
   "citations": {
    "6013574/XD5B9TZQ": {
     "URL": "https://www.ppgee.ufmg.br/defesas/1393M.PDF",
     "author": [
      {
       "family": "Rezende",
       "given": "Tamires"
      }
     ],
     "genre": "Master Thesis",
     "id": "6013574/XD5B9TZQ",
     "issued": {
      "year": 2016
     },
     "language": "Portuguese",
     "publisher": "UFMG",
     "title": "Aplicação de Técnicas de Inteligência Computacional para Análise da Expressão Facial em Reconhecimento de Sinais de Libras",
     "type": "thesis"
    }
   }
  },
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
