C:\Users\rubiarg\Anaconda3\envs\tensorflow\python.exe C:/Users/rubiarg/PycharmProjects/randomforest/rf-libras-ex2.py
Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   14.1s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.1min finished
Best Params ::
{'bootstrap': True,
 'max_depth': 10,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 200}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.79      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   22.2s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.6min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.3min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 90,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 7,
 'n_estimators': 600}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   20.1s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.5min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.2min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 50,
 'max_features': 'log2',
 'min_samples_leaf': 1,
 'min_samples_split': 2,
 'n_estimators': 200}
Train Accuracy ::  1.0
Test Accuracy  ::  65.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 1 0 1]]
C:\Users\rubiarg\Anaconda3\envs\tensorflow\lib\site-packages\sklearn\metrics\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       0.00      0.00      0.00         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
  'precision', 'predicted', average, warn_for)
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       1.00      1.00      1.00         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       0.67      1.00      0.80         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.20      0.50      0.29         2

                 avg / total       0.65      0.65      0.62        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   13.8s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.0min finished
Best Params ::
{'bootstrap': True,
 'max_depth': 70,
 'max_features': 'sqrt',
 'min_samples_leaf': 1,
 'min_samples_split': 2,
 'n_estimators': 200}
Train Accuracy ::  1.0
Test Accuracy  ::  80.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 1 0 0 0 0 0 0 1]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.50      0.50      0.50         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.33      0.50      0.40         2

                 avg / total       0.85      0.80      0.80        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.8s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.0min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 80,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 200}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.6s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.0min finished
Best Params ::
{'bootstrap': True,
 'max_depth': 60,
 'max_features': 'sqrt',
 'min_samples_leaf': 1,
 'min_samples_split': 7,
 'n_estimators': 200}
Train Accuracy ::  1.0
C:\Users\rubiarg\Anaconda3\envs\tensorflow\lib\site-packages\sklearn\metrics\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
Test Accuracy  ::  70.0
  'precision', 'predicted', average, warn_for)
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       0.00      0.00      0.00         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.20      0.50      0.29         2

                 avg / total       0.69      0.70      0.68        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   17.1s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.9min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 70,
 'max_features': 'log2',
 'min_samples_leaf': 1,
 'min_samples_split': 2,
 'n_estimators': 1800}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 1 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       1.00      1.00      1.00         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       0.67      1.00      0.80         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.6s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.1min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 100,
 'max_features': 'log2',
 'min_samples_leaf': 1,
 'min_samples_split': 2,
 'n_estimators': 1000}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 0 0 2]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       1.00      1.00      1.00         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.40      1.00      0.57         2

                 avg / total       0.81      0.75      0.74        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.5s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.1min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 80,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 1600}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   38.0s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.6min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.0min finished
Best Params ::
{'bootstrap': False,
 'max_depth': None,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 7,
 'n_estimators': 1200}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   41.3s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.6min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.8min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 20,
 'max_features': 'sqrt',
 'min_samples_leaf': 1,
 'min_samples_split': 5,
 'n_estimators': 200}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.79      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   35.9s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.5min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.0min finished
Best Params ::
{'bootstrap': False,
 'max_depth': None,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 7,
 'n_estimators': 600}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   32.0s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.7min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.0min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 110,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 600}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.6s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.3min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.0min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 20,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 5,
 'n_estimators': 1600}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.5s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.4min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 30,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 800}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.4s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.6min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.3min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 10,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 400}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.79      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   40.6s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.1min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.9min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 110,
 'max_features': 'log2',
 'min_samples_leaf': 1,
 'min_samples_split': 2,
 'n_estimators': 800}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 0 0 2]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       1.00      1.00      1.00         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.40      1.00      0.57         2

                 avg / total       0.81      0.75      0.74        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.2s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.0min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 90,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 5,
 'n_estimators': 1400}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.7s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.9min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  3.4min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 110,
 'max_features': 'log2',
 'min_samples_leaf': 2,
 'min_samples_split': 2,
 'n_estimators': 800}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 1 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       1.00      1.00      1.00         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       0.67      1.00      0.80         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   36.7s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.2min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.9min finished
Best Params ::
{'bootstrap': True,
 'max_depth': 100,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 400}
C:\Users\rubiarg\Anaconda3\envs\tensorflow\lib\site-packages\sklearn\metrics\classification.py:1135: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples.
  'precision', 'predicted', average, warn_for)
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       0.00      0.00      0.00         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.20      0.50      0.29         2

                 avg / total       0.69      0.70      0.68        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.9s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min
Best Params ::
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.2min finished
{'bootstrap': True,
 'max_depth': 40,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 5,
 'n_estimators': 1400}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.79      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   26.7s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  2.6min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  4.0min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 30,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 7,
 'n_estimators': 2000}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   16.6s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.2min finished
Best Params ::
{'bootstrap': True,
 'max_depth': 110,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 1600}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.79      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   18.9s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.8min finished
Best Params ::
{'bootstrap': False,
 'max_depth': None,
 'max_features': 'log2',
 'min_samples_leaf': 1,
 'min_samples_split': 5,
 'n_estimators': 1400}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 0 0 0 1 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       1.00      1.00      1.00         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       0.67      1.00      0.80         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.79      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.4s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.2min finished
Best Params ::
{'bootstrap': True,
 'max_depth': 20,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 7,
 'n_estimators': 2000}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 0 2 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      1.00      1.00         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.79      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   19.7s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.2min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 60,
 'max_features': 'sqrt',
 'min_samples_leaf': 1,
 'min_samples_split': 7,
 'n_estimators': 400}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 1 0 0 0 0 0 0 1]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.50      0.50      0.50         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.33      0.50      0.40         2

                 avg / total       0.82      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.5s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.4min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.6min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 50,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 7,
 'n_estimators': 200}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 1 0 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.50      1.00      0.67         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.78      0.70      0.70        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   27.0s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.9min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.7min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 40,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 2,
 'n_estimators': 200}
Train Accuracy ::  1.0
Test Accuracy  ::  75.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 1 0 0 0 0 0 0 1]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.50      0.50      0.50         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.33      0.50      0.40         2

                 avg / total       0.82      0.75      0.75        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   21.0s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.2min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  1.9min finished
Best Params ::
{'bootstrap': False,
 'max_depth': 90,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 7,
 'n_estimators': 1800}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 0 1 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.67      1.00      0.80         2
data-libras\samplefelicidade       0.67      1.00      0.80         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.76      0.70      0.69        20

Fitting 3 folds for each of 100 candidates, totalling 300 fits
[Parallel(n_jobs=-1)]: Done  42 tasks      | elapsed:   15.5s
[Parallel(n_jobs=-1)]: Done 192 tasks      | elapsed:  1.3min
[Parallel(n_jobs=-1)]: Done 300 out of 300 | elapsed:  2.0min finished
Best Params ::
{'bootstrap': False,
 'max_depth': None,
 'max_features': 'sqrt',
 'min_samples_leaf': 4,
 'min_samples_split': 7,
 'n_estimators': 600}
Train Accuracy ::  1.0
Test Accuracy  ::  70.0
Confusion matrix ::
 [[2 0 0 0 0 0 0 0 0 0]
 [0 1 0 0 0 0 0 0 0 1]
 [0 0 0 0 0 0 0 0 0 2]
 [0 0 0 2 0 0 0 0 0 0]
 [0 0 0 0 2 0 0 0 0 0]
 [0 0 0 0 0 2 0 0 0 0]
 [0 0 0 0 1 0 1 0 0 0]
 [0 0 0 0 0 0 0 2 0 0]
 [0 0 1 0 0 0 0 0 1 0]
 [0 0 0 0 1 0 0 0 0 1]]
                              precision    recall  f1-score   support

   data-libras\sampleacalmar       1.00      1.00      1.00         2
    data-libras\sampleacusar       1.00      0.50      0.67         2
 data-libras\sampleaniquilar       0.00      0.00      0.00         2
data-libras\sampleapaixonado       1.00      1.00      1.00         2
  data-libras\sampleengordar       0.50      1.00      0.67         2
data-libras\samplefelicidade       1.00      1.00      1.00         2
     data-libras\samplemagro       1.00      0.50      0.67         2
   data-libras\samplesortudo       1.00      1.00      1.00         2
  data-libras\samplesurpresa       1.00      0.50      0.67         2
   data-libras\samplezangado       0.25      0.50      0.33         2

                 avg / total       0.78      0.70      0.70        20


Process finished with exit code 0
